<!DOCTYPE HTML>
<!--
	TXT by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Project 1</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<header id="header">
					<div class="logo container">
						<div>
							<!-- <h4> <a href="index.html" target = "projects" class="button" > Back</a></h4> -->
							<h5>  <a href="javascript:history.back()" class="button" > Go Back </a> </h5>
							
						</div>
					</div>
				</header>

				<article id="project1" class="wrapper style1" >
					<div class="container">
						<div class="row">
							
							<div class="col-3 col4-small col-12-medium">
								<br> 
								<br> 
								<span class="image fit"><img src="images/MultipleObjectScreenshot.png" alt="" /></span>
								
								<a href="http://engineering.nyu.edu/mechatronics/videos/AR-HRI.html" ><span class="label"> Video </span> </a> <br> 
								<a href="https://ieeexplore.ieee.org/abstract/document/8967973" ><span class="label"> Publication </span> </a>
								
							</div>

							<div class="col-4 col-9-xlarge col-12-medium">
									<!-- <header> -->
									<h2> <strong> Abstract </strong></h2>
									<!--</header> -->
								<p style="text-align:justify"> As robots start to become ubiquitous in the
									personal workspace, it is necessary to have simple and intuitive
									interfaces to interact with them. In this paper, we propose an
									augmented reality (AR) interface for human-robot interaction
									(HRI) in a shared working environment. By fusing markerbased
									and markerless AR technologies, a mobile AR interface is
									created that enables a smartphone to detect planar surfaces and
									localize a manipulator robot in its working environment while
									obviating the need for a controlled or constrained environment.
									The AR interface and robot manipulator are integrated to render
									a system that enables users to perform pick-and-place task
									effortlessly. Specifically, a smartphone-based AR application
									is developed that allows a user to select any location within
									the robot’s workspace by merely touching on the smartphone
									screen. Virtual objects, rendered at user-selected locations, are
									used to determine the pick and place locations of objects
									in the real world. The virtual object’s start and end points,
									originally specified in the smartphone camera coordinate frame,
									are transformed into the robot coordinate frame for the robot
									manipulator to autonomously perform the assigned task. </p>
								<p> Go to Home page </p>
								<a href="index.html" class="button"> Home</a>
							</div>
							
						</div>
					</div>
				</article>

		</div>	

	</body>
</html>